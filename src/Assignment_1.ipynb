{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Assignment 1\n",
      "(111993, 12)\n",
      "            Instance  Year of Record            Age  Size of City  \\\n",
      "count  111993.000000   111552.000000  111499.000000  1.119930e+05   \n",
      "mean    55997.000000     1999.421274      37.345304  8.388538e+05   \n",
      "std     32329.738686       11.576382      16.036694  2.196879e+06   \n",
      "min         1.000000     1980.000000      14.000000  7.700000e+01   \n",
      "25%     27999.000000     1989.000000      24.000000  7.273400e+04   \n",
      "50%     55997.000000     1999.000000      35.000000  5.060920e+05   \n",
      "75%     83995.000000     2009.000000      48.000000  1.184501e+06   \n",
      "max    111993.000000     2019.000000     115.000000  4.999251e+07   \n",
      "\n",
      "       Wears Glasses  Body Height [cm]  Income in EUR  \n",
      "count  111993.000000     111993.000000   1.119930e+05  \n",
      "mean        0.500531        175.220192   1.092138e+05  \n",
      "std         0.500002         19.913889   1.498024e+05  \n",
      "min         0.000000         94.000000  -5.696906e+03  \n",
      "25%         0.000000        160.000000   3.077169e+04  \n",
      "50%         1.000000        174.000000   5.733917e+04  \n",
      "75%         1.000000        190.000000   1.260936e+05  \n",
      "max         1.000000        265.000000   5.285252e+06  \n"
     ]
    }
   ],
   "source": [
    "## Start of Notebook\n",
    "\n",
    "print('Starting Assignment 1')\n",
    "RawData = main.ReadInData(\"../data/tcd ml 2019-20 income prediction training (with labels).csv\")\n",
    "print(RawData.shape)\n",
    "print(RawData.describe())\n",
    "\n",
    "## Might not need this line here. Just a precaution for NaN.\n",
    "# if trainingData.isnull().any:\n",
    "#     trainingData = trainingData.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "1999.4212743832472\n",
      "Number of null values in each column:\n",
      "Year of Record      0\n",
      "Age                 0\n",
      "Country             0\n",
      "Size of City        0\n",
      "Profession          0\n",
      "Wears Glasses       0\n",
      "Body Height [cm]    0\n",
      "Income in EUR       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Dropping Features that are missing a large amount of data\n",
    "## Dropping instances with missing data\n",
    "\n",
    "RawData = main.HandleMissingData(RawData)\n",
    "\n",
    "null_counts = RawData.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "Year of Record      0\n",
      "Age                 0\n",
      "Country             0\n",
      "Size of City        0\n",
      "Profession          0\n",
      "Wears Glasses       0\n",
      "Body Height [cm]    0\n",
      "Income in EUR       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Checking data for missing values\n",
    "\n",
    "null_counts = RawData.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in Year of Record\n",
      "[1997. 1996. 2018. 2006. 2010. 1991. 1982. 2008. 2015. 2019. 1981. 1989.\n",
      " 2003. 1987. 1995. 1992. 1980. 1983. 2011. 2014. 1985. 2005. 1998. 2001.\n",
      " 2017. 2007. 1988. 1994. 2012. 2009. 2013. 2004. 1999. 2002. 1993. 2000.\n",
      " 1990. 2016. 1986. 1984.]\n",
      "40\n",
      "Features in Age\n",
      "[ 41.  28.  33.  46.  60.  71.  36.  43.  16.  51.  15.  22.  32.  40.\n",
      "  31.  27.  25.  35.  63.  38.  34.  20.  23.  14.  37.  62.  52.  47.\n",
      "  24.  26.  50.  49.  18.  19.  39.  66.  21.  44.  29.  64.  65.  53.\n",
      "  78.  42.  58.  17.  30.  79.  48.  56.  83.  54.  74.  87.  90.  67.\n",
      "  45.  77.  73.  55.  92.  80.  72.  57.  70.  59.  61.  82.  69.  98.\n",
      "  94.  68.  81.  97.  76.  75.  88.  91.  96.  84.  89. 107.  85.  86.\n",
      " 100. 110.  95.  99.  93. 104. 102. 101. 105. 111. 108. 103. 109. 106.\n",
      " 115.]\n",
      "99\n",
      "Features in Country\n",
      "['Belarus' 'Singapore' 'Norway' 'Cuba' 'United Arab Emirates' 'Liberia'\n",
      " 'State of Palestine' 'Israel' 'South Sudan' 'Kyrgyzstan' 'Togo' 'Finland'\n",
      " 'Sierra Leone' 'Papua New Guinea' 'Czechia' 'Paraguay' 'Belgium'\n",
      " 'Costa Rica' 'Senegal' 'Congo' 'Slovakia' 'Burundi' 'Portugal' 'Tunisia'\n",
      " 'Lebanon' 'Azerbaijan' 'Chile' 'Botswana' 'Jordan' 'Zimbabwe' 'Rwanda'\n",
      " 'Greece' 'Turkmenistan' 'Sweden' 'El Salvador' 'Somalia' 'Haiti'\n",
      " 'Tajikistan' 'Hungary' 'Peru' 'Laos' 'Austria' 'Bolivia' 'Kazakhstan'\n",
      " 'Nicaragua' 'Moldova' 'Gabon' 'Bulgaria' 'Namibia' 'Croatia'\n",
      " 'Central African Republic' 'Ghana' 'Denmark' 'Cambodia' 'Netherlands'\n",
      " 'Niger' 'Mozambique' 'Ireland' 'Mongolia' 'Luxembourg' 'Benin' 'Kuwait'\n",
      " 'Serbia' 'Chad' 'North Korea' 'Dominican Republic' 'Burkina Faso'\n",
      " 'Switzerland' 'Ecuador' 'Honduras' 'Libya' 'Syria' 'Uruguay' 'Qatar'\n",
      " 'Mauritania' 'Jamaica' 'Guinea-Bissau' 'Panama' 'Cameroon'\n",
      " 'Bosnia and Herzegovina' 'North Macedonia' 'Oman' 'Eritrea' 'Australia'\n",
      " 'Guinea' 'Saudi Arabia' 'Albania' 'Slovenia' 'Lesotho' 'Malawi' 'Morocco'\n",
      " 'Georgia' 'New Zealand' 'Argentina' 'Uzbekistan' 'Guatemala' 'Zambia'\n",
      " 'Gambia' 'Trinidad and Tobago' 'Timor-Leste' 'Mali' \"CÃ´te d'Ivoire\"\n",
      " 'Yemen' 'Eswatini' 'Venezuela' 'Armenia' 'Nepal' 'Sri Lanka' 'Bahrain'\n",
      " 'Cyprus' 'Romania' 'Lithuania' 'Madagascar' 'Mauritius'\n",
      " 'Equatorial Guinea' 'Ukraine' 'Latvia' 'Fiji' 'Comoros' 'Estonia'\n",
      " 'Poland' 'Canada' 'Djibouti' 'Angola' 'Malaysia' 'Guyana' 'Barbados'\n",
      " 'Spain' 'Afghanistan' 'Iraq' 'Bhutan' 'Saint Lucia' 'South Korea'\n",
      " 'Cabo Verde' 'Bahamas' 'Colombia' 'Montenegro' 'Tanzania'\n",
      " 'Solomon Islands' 'Suriname' 'Uganda' 'Malta' 'Algeria' 'Sudan' 'Brunei'\n",
      " 'Maldives' 'Belize' 'Vanuatu' 'Tonga' 'Thailand' 'Micronesia' 'Grenada'\n",
      " 'DR Congo' 'Seychelles' 'South Africa' 'Kenya' 'Kiribati'\n",
      " 'United Kingdom' 'Vietnam' 'Myanmar']\n",
      "160\n",
      "Features in Size of City\n",
      "[1239930 1603504 1298017 ...   60848  848640  325590]\n",
      "104349\n",
      "Features in Profession\n",
      "['steel workers' 'safe event coordinator' 'receivables/payables analyst'\n",
      " ... 'blake fellow' 'accountant' 'audit supervisor']\n",
      "1341\n",
      "Features in Wears Glasses\n",
      "[0 1]\n",
      "2\n",
      "Features in Body Height [cm]\n",
      "[193 186 170 171 188 181 174 190 189 157 208 191 198 182 165 152 201 167\n",
      " 185 154 179 177 153 180 139 206 163 161 219 213 192 151 149 150 204 199\n",
      " 155 147 160 173 205 196 176 146 183 178 156 159 175 203 168 224 158 141\n",
      " 187 164 172 140 202 210 236 143 184 215 230 169 162 232 145 121 166 137\n",
      " 200 211 207 197 195 209 129 194 148 221 220 214 131 136 142 138 116 212\n",
      " 120 144 133 132 123 217 127 135 134 128 111 225 125 229 218 222 216 226\n",
      " 227 235 126 239 233 228 234 238 130 223 231 237 124 110 107 244 242 115\n",
      " 106 118 114 122 119 251 113 117 255 243 104 241 101 105 245 265 246 240\n",
      " 247 108 256  95 248 249 250 109 253 261  94 112]\n",
      "156\n",
      "Features in Income in EUR\n",
      "[ 61031.94416  91001.32764 157982.1767  ... 289951.3294  100046.5278\n",
      " 145886.2885 ]\n",
      "111991\n"
     ]
    }
   ],
   "source": [
    "## Seeing the data and the unique values\n",
    "\n",
    "for s in RawData.columns.values:\n",
    "    print(\"Features in \" + s)\n",
    "    print(RawData[s].unique())\n",
    "    print(len(RawData[s].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## Section to conver to binary matrix\n",
    "## Changing Country, Profession\n",
    "\n",
    "RawData_Country = pd.get_dummies(RawData.Country)\n",
    "print(type(RawData_Country))\n",
    "RawData_Profession = pd.get_dummies(RawData.Profession)\n",
    "print(type(RawData_Profession))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year of Record</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size of City</th>\n",
       "      <th>Wears Glasses</th>\n",
       "      <th>Body Height [cm]</th>\n",
       "      <th>Income in EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>111993.000000</td>\n",
       "      <td>111993.000000</td>\n",
       "      <td>1.119930e+05</td>\n",
       "      <td>111993.000000</td>\n",
       "      <td>111993.000000</td>\n",
       "      <td>1.119930e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1999.419616</td>\n",
       "      <td>37.343780</td>\n",
       "      <td>8.388538e+05</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>175.220192</td>\n",
       "      <td>1.092138e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>11.553597</td>\n",
       "      <td>16.001302</td>\n",
       "      <td>2.196879e+06</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>19.913889</td>\n",
       "      <td>1.498024e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>-5.696906e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.273400e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>3.077169e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.060920e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>5.733917e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.184501e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.260936e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>4.999251e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>5.285252e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year of Record            Age  Size of City  Wears Glasses  \\\n",
       "count   111993.000000  111993.000000  1.119930e+05  111993.000000   \n",
       "mean      1999.419616      37.343780  8.388538e+05       0.500531   \n",
       "std         11.553597      16.001302  2.196879e+06       0.500002   \n",
       "min       1980.000000      14.000000  7.700000e+01       0.000000   \n",
       "25%       1989.000000      24.000000  7.273400e+04       0.000000   \n",
       "50%       1999.000000      35.000000  5.060920e+05       1.000000   \n",
       "75%       2009.000000      48.000000  1.184501e+06       1.000000   \n",
       "max       2019.000000     115.000000  4.999251e+07       1.000000   \n",
       "\n",
       "       Body Height [cm]  Income in EUR  \n",
       "count     111993.000000   1.119930e+05  \n",
       "mean         175.220192   1.092138e+05  \n",
       "std           19.913889   1.498024e+05  \n",
       "min           94.000000  -5.696906e+03  \n",
       "25%          160.000000   3.077169e+04  \n",
       "50%          174.000000   5.733917e+04  \n",
       "75%          190.000000   1.260936e+05  \n",
       "max          265.000000   5.285252e+06  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RawData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year of Record', 'Age', 'Country', 'Size of City', 'Profession',\n",
      "       'Wears Glasses', 'Body Height [cm]', 'Income in EUR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Creating clean training data\n",
    "print(RawData.columns)\n",
    "\n",
    "RawData = pd.concat([RawData, RawData_Country], axis=1)\n",
    "RawData= RawData.drop('Country', axis=1)\n",
    "RawData = pd.concat([RawData, RawData_Profession], axis=1)\n",
    "RawData= RawData.drop('Profession', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Year of Record</th>\n",
       "      <th>Age</th>\n",
       "      <th>Size of City</th>\n",
       "      <th>Wears Glasses</th>\n",
       "      <th>Body Height [cm]</th>\n",
       "      <th>Income in EUR</th>\n",
       "      <th>Afghanistan</th>\n",
       "      <th>Albania</th>\n",
       "      <th>Algeria</th>\n",
       "      <th>...</th>\n",
       "      <th>windows administrator</th>\n",
       "      <th>wireless coordinator</th>\n",
       "      <th>woodworker</th>\n",
       "      <th>word processor</th>\n",
       "      <th>workforce management analyst</th>\n",
       "      <th>workforce planning intern</th>\n",
       "      <th>writer</th>\n",
       "      <th>x-ray technician</th>\n",
       "      <th>yardmaster</th>\n",
       "      <th>youth initiatives lead advisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>1.107390e+05</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>1.107390e+05</td>\n",
       "      <td>110739.00000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "      <td>110739.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>55977.659343</td>\n",
       "      <td>1999.412790</td>\n",
       "      <td>37.341154</td>\n",
       "      <td>8.378984e+05</td>\n",
       "      <td>0.500673</td>\n",
       "      <td>175.222352</td>\n",
       "      <td>1.090052e+05</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>32331.256601</td>\n",
       "      <td>11.577877</td>\n",
       "      <td>16.033197</td>\n",
       "      <td>2.187687e+06</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>19.918049</td>\n",
       "      <td>1.493287e+05</td>\n",
       "      <td>0.01377</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>0.007950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0.016997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>-5.696906e+03</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>27978.500000</td>\n",
       "      <td>1989.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.274450e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>3.074007e+04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>55973.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.060690e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>5.728304e+04</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>83984.500000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.184484e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.258811e+05</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>111993.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>4.999251e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>5.285252e+06</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã 1507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Instance  Year of Record            Age  Size of City  \\\n",
       "count  110739.000000   110739.000000  110739.000000  1.107390e+05   \n",
       "mean    55977.659343     1999.412790      37.341154  8.378984e+05   \n",
       "std     32331.256601       11.577877      16.033197  2.187687e+06   \n",
       "min         1.000000     1980.000000      14.000000  7.700000e+01   \n",
       "25%     27978.500000     1989.000000      24.000000  7.274450e+04   \n",
       "50%     55973.000000     1999.000000      35.000000  5.060690e+05   \n",
       "75%     83984.500000     2009.000000      48.000000  1.184484e+06   \n",
       "max    111993.000000     2019.000000     115.000000  4.999251e+07   \n",
       "\n",
       "       Wears Glasses  Body Height [cm]  Income in EUR   Afghanistan  \\\n",
       "count  110739.000000     110739.000000   1.107390e+05  110739.00000   \n",
       "mean        0.500673        175.222352   1.090052e+05       0.00019   \n",
       "std         0.500002         19.918049   1.493287e+05       0.01377   \n",
       "min         0.000000         94.000000  -5.696906e+03       0.00000   \n",
       "25%         0.000000        160.000000   3.074007e+04       0.00000   \n",
       "50%         1.000000        174.000000   5.728304e+04       0.00000   \n",
       "75%         1.000000        190.000000   1.258811e+05       0.00000   \n",
       "max         1.000000        265.000000   5.285252e+06       1.00000   \n",
       "\n",
       "             Albania        Algeria  ...  windows administrator  \\\n",
       "count  110739.000000  110739.000000  ...          110739.000000   \n",
       "mean        0.003558       0.000063  ...               0.000244   \n",
       "std         0.059542       0.007950  ...               0.015613   \n",
       "min         0.000000       0.000000  ...               0.000000   \n",
       "25%         0.000000       0.000000  ...               0.000000   \n",
       "50%         0.000000       0.000000  ...               0.000000   \n",
       "75%         0.000000       0.000000  ...               0.000000   \n",
       "max         1.000000       1.000000  ...               1.000000   \n",
       "\n",
       "       wireless coordinator     woodworker  word processor   \\\n",
       "count         110739.000000  110739.000000    110739.000000   \n",
       "mean               0.000244       0.000307         0.000253   \n",
       "std                0.015613       0.017520         0.015899   \n",
       "min                0.000000       0.000000         0.000000   \n",
       "25%                0.000000       0.000000         0.000000   \n",
       "50%                0.000000       0.000000         0.000000   \n",
       "75%                0.000000       0.000000         0.000000   \n",
       "max                1.000000       1.000000         1.000000   \n",
       "\n",
       "       workforce management analyst  workforce planning intern         writer  \\\n",
       "count                 110739.000000              110739.000000  110739.000000   \n",
       "mean                       0.000280                   0.000217       0.000289   \n",
       "std                        0.016729                   0.014720       0.016997   \n",
       "min                        0.000000                   0.000000       0.000000   \n",
       "25%                        0.000000                   0.000000       0.000000   \n",
       "50%                        0.000000                   0.000000       0.000000   \n",
       "75%                        0.000000                   0.000000       0.000000   \n",
       "max                        1.000000                   1.000000       1.000000   \n",
       "\n",
       "       x-ray technician     yardmaster  youth initiatives lead advisor  \n",
       "count     110739.000000  110739.000000                   110739.000000  \n",
       "mean           0.000253       0.000181                        0.000289  \n",
       "std            0.015899       0.013438                        0.016997  \n",
       "min            0.000000       0.000000                        0.000000  \n",
       "25%            0.000000       0.000000                        0.000000  \n",
       "50%            0.000000       0.000000                        0.000000  \n",
       "75%            0.000000       0.000000                        0.000000  \n",
       "max            1.000000       1.000000                        1.000000  \n",
       "\n",
       "[8 rows x 1507 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RawData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Training Data to new file\n",
    "RawData.to_csv(\"../data/processedData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in new data and model\n",
    "\n",
    "CleanData = main.ReadInData(\"../data/processedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = CleanData['Income in EUR']\n",
    "features = CleanData.drop(labels=['Income in EUR', 'Instance'], axis=1)\n",
    "\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Data\n",
    "\n",
    "features_train, features_val, income_train, income_val = train_test_split(features, income, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Linear Regression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(features_train, income_train)\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict with the validation data\n",
    "\n",
    "income_predict = model.predict(features_val)\n",
    "comparison = pd.DataFrame({'Actual': income_val, 'Predicted': income_predict})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graphing Difference \n",
    "\n",
    "df1 = comparison.head(25)\n",
    "df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(income_val, income_predict))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(income_val, income_predict))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(income_val, income_predict)))\n",
    "\n",
    "## Mean Absolute Error: 43557.00458896904\n",
    "# Mean Squared Error: 7422065078.367375\n",
    "# Root Mean Squared Error: 86151.40787223025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in Test and try to map\n",
    "\n",
    "TestData = main.ReadInData(\"../data/tcd ml 2019-20 income prediction test (without labels).csv\")\n",
    "TestData.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing Training and Test (Country)\n",
    "print(TestData['Country'].unique())\n",
    "print(\"Test Shape \" + str(len(TestData['Country'].unique())))\n",
    "Raw = main.ReadInData(\"../data/tcd ml 2019-20 income prediction training (with labels).csv\")\n",
    "print(Raw['Country'].unique())\n",
    "print(\"Raw Shape \" + str(len(Raw['Country'].unique())))\n",
    "\n",
    "print(TestData['Country'].equals(Raw['Country']))\n",
    "\n",
    "## Test has less than 3 to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing Training and Test (Profession)\n",
    "print(TestData['Profession'].unique())\n",
    "print(\"Test Shape \" + str(len(TestData['Profession'].unique())))\n",
    "print(Raw['Profession'].unique())\n",
    "print(\"Raw Shape \" + str(len(Raw['Profession'].unique())))\n",
    "\n",
    "print(TestData['Profession'].equals(Raw['Profession']))\n",
    "\n",
    "## Test Data has less 15 to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing Training and Test (University Degree)\n",
    "print(TestData['University Degree'].unique())\n",
    "print(\"Test Shape \" + str(len(TestData['University Degree'].unique())))\n",
    "print(Raw['University Degree'].unique())\n",
    "print(\"Raw Shape \" + str(len(Raw['University Degree'].unique())))\n",
    "\n",
    "print(TestData['University Degree'].equals(Raw['University Degree']))\n",
    "\n",
    "## Test Data has less 15 to Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell to Compare what is in Test and Trainning Data\n",
    "\n",
    "Diff = pd.DataFrame(columns=['Unique_C_InTest', 'Unique_C_InTrain','Unique_P_InTest', 'Unique_P_InTrain'])\n",
    "\n",
    "Diff = pd.DataFrame()\n",
    "Diff['Unique_C_InTest'] = TestData[\"Country\"][~TestData[\"Country\"].isin(Raw[\"Country\"])].drop_duplicates()\n",
    "print(Diff['Unique_C_InTest'])\n",
    "print(str(len(Diff['Unique_C_InTest'])))\n",
    "\n",
    "Diff = pd.DataFrame()\n",
    "Diff['Unique_P_InTest',] = TestData[\"Profession\"][~TestData[\"Profession\"].isin(Raw[\"Profession\"])].drop_duplicates()\n",
    "print(Diff['Unique_P_InTest',])\n",
    "print(str(len(Diff['Unique_P_InTest',])))\n",
    "\n",
    "Diff = pd.DataFrame()\n",
    "Diff['Unique_C_InTrain'] = Raw[\"Country\"][~Raw[\"Country\"].isin(TestData[\"Country\"])].drop_duplicates()\n",
    "print(Diff['Unique_C_InTrain'])\n",
    "print(str(len(Diff['Unique_C_InTrain'])))\n",
    "\n",
    "Diff = pd.DataFrame()\n",
    "Diff['Unique_P_InTrain'] = Raw[\"Profession\"][~Raw[\"Profession\"].isin(TestData[\"Profession\"])].drop_duplicates()\n",
    "print(Diff['Unique_P_InTrain'])\n",
    "print(str(len(Diff['Unique_P_InTrain'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw = main.HandleMissingData(Raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = Raw.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = main.HandleMissingData(TestData)\n",
    "null_counts = TestData.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell used to test PrepTestForModel\n",
    "\n",
    "train = main.ReadInData(\"../data/processedData2.csv\")\n",
    "Raw = main.ReadInData(\"../data/tcd ml 2019-20 income prediction training (with labels).csv\")\n",
    "test = main.ReadInData(\"../data/tcd ml 2019-20 income prediction test (without labels).csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell used to test PrepTestForModel\n",
    "test = main.ReadInData(\"../data/tcd ml 2019-20 income prediction test (without labels).csv\")\n",
    "test = main.HandleMissingData(test)\n",
    "CleanTest = test.drop('Country', axis=1)\n",
    "CleanTest = CleanTest.drop('Profession', axis=1)\n",
    "CleanTest = CleanTest.drop('Income', axis=1)\n",
    "\n",
    "# Create 1st DF as copy. Create 2nd DF with encoding. Cat together\n",
    "\n",
    "print(CleanTest.columns.unique)\n",
    "print(train.columns.unique)\n",
    "countries = Raw['Country'].unique()\n",
    "professions = Raw['Profession'].unique()\n",
    "\n",
    "countryDf = pd.DataFrame(columns=countries)\n",
    "professionDf = pd.DataFrame(columns=professions)\n",
    "\n",
    "count = 0\n",
    "series = [0] * len(countries)\n",
    "    \n",
    "for i in test['Country']:\n",
    "    countryDf.loc[count] = series\n",
    "    if i in countries:\n",
    "        # Write output\n",
    "        # \"I think this is right... it is right\"\n",
    "        countryDf.loc[count][i] = 1\n",
    "        \n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "print(countryDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([22]),)\n",
      "Portugal\n"
     ]
    }
   ],
   "source": [
    "results = np.where(countries == 'Portugal')\n",
    "print(results)\n",
    "print(countries[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Belarus Singapore Norway Cuba United Arab Emirates Liberia  \\\n",
      "0           0         0      0    0                    0       0   \n",
      "1           0         0      0    0                    0       0   \n",
      "2           0         0      0    0                    0       0   \n",
      "3           0         0      0    0                    0       0   \n",
      "4           0         0      0    0                    0       0   \n",
      "...       ...       ...    ...  ...                  ...     ...   \n",
      "17048       0         0      0    0                    0       0   \n",
      "17049       0         0      0    0                    0       0   \n",
      "17050       0         0      0    0                    0       0   \n",
      "17051       0         0      0    0                    0       0   \n",
      "17052       0         0      0    0                    0       0   \n",
      "\n",
      "      State of Palestine Israel South Sudan Kyrgyzstan  ... Micronesia  \\\n",
      "0                      0      0           0          0  ...          0   \n",
      "1                      0      0           0          1  ...          0   \n",
      "2                      0      0           0          0  ...          0   \n",
      "3                      0      0           0          0  ...          0   \n",
      "4                      0      0           0          0  ...          0   \n",
      "...                  ...    ...         ...        ...  ...        ...   \n",
      "17048                  0      0           0          0  ...          0   \n",
      "17049                  0      0           0          0  ...          0   \n",
      "17050                  0      0           0          0  ...          0   \n",
      "17051                  0      0           0          0  ...          0   \n",
      "17052                  0      0           0          0  ...          0   \n",
      "\n",
      "      Grenada DR Congo Seychelles South Africa Kenya Kiribati United Kingdom  \\\n",
      "0           0        0          0            0     0        0              0   \n",
      "1           0        0          0            0     0        0              0   \n",
      "2           0        0          0            0     0        0              0   \n",
      "3           0        0          0            0     0        0              0   \n",
      "4           0        0          0            0     0        0              0   \n",
      "...       ...      ...        ...          ...   ...      ...            ...   \n",
      "17048       0        0          0            0     0        0              0   \n",
      "17049       0        0          0            0     0        0              0   \n",
      "17050       0        0          0            0     0        0              0   \n",
      "17051       0        0          0            0     0        0              0   \n",
      "17052       0        0          0            0     0        0              0   \n",
      "\n",
      "      Vietnam Myanmar  \n",
      "0           0       0  \n",
      "1           0       0  \n",
      "2           0       0  \n",
      "3           0       0  \n",
      "4           0       0  \n",
      "...       ...     ...  \n",
      "17048       0       0  \n",
      "17049       0       0  \n",
      "17050       0       0  \n",
      "17051       0       0  \n",
      "17052       0       0  \n",
      "\n",
      "[17053 rows x 160 columns]\n"
     ]
    }
   ],
   "source": [
    "print(countryDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
